{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2asHTyeq--Hl"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"HW2_part2.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1GSxKIWEzBpY3zzcA2C5rfsccdW7tERHo\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.rcParams['axes.labelsize'] = 14  # fontsize of the x any y labels\n",
        "plt.rcParams['xtick.labelsize'] = 12 # fontsize of the x tick labels\n",
        "plt.rcParams['ytick.labelsize'] = 12 # fontsize of the y tick labels\n",
        "\n",
        "# Sklearn imports\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score,precision_score, recall_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#Scipy imports\n",
        "from scipy import stats\n",
        "\n",
        "#import itertools\n",
        "import itertools\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\"\"\"# 1. Read data from this URL http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\"\"\n",
        "\n",
        "data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', header=None)\n",
        "data\n",
        "\n",
        "\"\"\"# 2. Defining and mapping features to data\n",
        "\n",
        "#### Define the column names based on the data description\n",
        "\"\"\"\n",
        "\n",
        "column_names = ['ID','Diagnosis']\n",
        "\n",
        "# Add mean real-valued features\n",
        "mean_features = ['Mean_Radius', 'Mean_Texture', 'Mean_Perimeter', 'Mean_Area',\n",
        "                 'Mean_Smoothness', 'Mean_Compactness', 'Mean_Concavity',\n",
        "                 'Mean_Concave_Points', 'Mean_Symmetry', 'Mean_Fractal_Dimension']\n",
        "\n",
        "# Add standard error feature names\n",
        "se_features = ['SE_Radius', 'SE_Texture', 'SE_Perimeter', 'SE_Area',\n",
        "               'SE_Smoothness', 'SE_Compactness', 'SE_Concavity',\n",
        "               'SE_Concave_Points', 'SE_Symmetry', 'SE_Fractal_Dimension']\n",
        "\n",
        "# Add worst feature names\n",
        "worst_features = ['Worst_Radius', 'Worst_Texture', 'Worst_Perimeter', 'Worst_Area',\n",
        "                  'Worst_Smoothness', 'Worst_Compactness', 'Worst_Concavity',\n",
        "                  'Worst_Concave_Points', 'Worst_Symmetry', 'Worst_Fractal_Dimension']\n",
        "\n",
        "\n",
        "# combine all columns\n",
        "all_columns = column_names + mean_features + se_features + worst_features\n",
        "\n",
        "# assign column names to dataframe\n",
        "data.columns = all_columns\n",
        "\n",
        "data.head()\n",
        "\n",
        "\"\"\"# 3. Exploratory Data Analysis (EDA)\"\"\"\n",
        "\n",
        "# Plot heatmap correlation matrix on a graph Reference: https://medium.com/@szabo.bibor/how-to-create-a-seaborn-correlation-heatmap-in-python-834c0686b88e\n",
        "plt.figure(figsize=(20,15))\n",
        "\n",
        "heatmap = sns.heatmap(data.corr(), vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
        "\n",
        "heatmap.set_title('Correlation Matrix Heatmap', fontdict={'fontsize': 18}, pad=12)\n",
        "\n",
        "\"\"\"### Check class imbalace\"\"\"\n",
        "\n",
        "fig = plt.figure(figsize=(5,3))\n",
        "ax = fig.add_subplot(111)\n",
        "data['Diagnosis'].value_counts().plot(kind='bar',\n",
        "                                     ax=ax,\n",
        "                                     color=['green','salmon'])\n",
        "\n",
        "# set title and labels\n",
        "ax.set_title('Proportion of observations of the response variable',\n",
        "             fontsize=10, loc='left')\n",
        "ax.set_xlabel('Diagnosis',\n",
        "              fontsize=7)\n",
        "ax.set_ylabel('proportion of observations',\n",
        "              fontsize=7)\n",
        "\n",
        "\"\"\"### Summary statistics\"\"\"\n",
        "\n",
        "# Using describe function to compute summary statistics of entire df. It automatically ignore cat features\n",
        "# Slice the dataset to skip first column as it is an ID\n",
        "data.iloc[:,1:].describe()[1:] # Skip first row as it returns instance counts and it is the same across all features (569)\n",
        "\n",
        "\"\"\"# 4. Encoding target variable\"\"\"\n",
        "\n",
        "data['Diagnosis']  = data['Diagnosis'].map({'M':1,'B':0})\n",
        "class_names = {0: 'Benign', 1: 'Malignant'}\n",
        "\n",
        "data.tail()\n",
        "\n",
        "class_names = {0: 'Benign', 1: 'Malignant'}\n",
        "\n",
        "\"\"\"# 5. Model building\"\"\"\n",
        "\n",
        "# Extract X and y\n",
        "X = data.drop(columns=['Diagnosis','ID'],axis=1)\n",
        "y = data.Diagnosis\n",
        "X.head()\n",
        "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y, random_state=42)\n",
        "\n",
        "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y, random_state=42)\n",
        "\n",
        "\"\"\"#### Scaling data for KNN ( Below codes were adopted from class code example) link: https://colab.research.google.com/drive/1Tk3iWD1MgSIUrhbvrEobmcA5PNG7Njkw?usp=sharing#scrollTo=Fe_Mfq1QsP3g\"\"\"\n",
        "\n",
        "# Instantiate StandardScaler\n",
        "sc = StandardScaler()\n",
        "# Fitting the StandardScaler\n",
        "sc.fit(X_train)\n",
        "\n",
        "# Transforming the datasets\n",
        "X_train_std = sc.transform(X_train) # Perform standardization of train set X attributes by centering and scaling\n",
        "                                    # This line uses the transform method of the sc object to standardize the features in the training set.\n",
        "X_test_std = sc.transform(X_test)   # Perform standardization of test set X attributes by centering and scaling\n",
        "                                    # Similarly, this line standardizes the features in the testing set.\n",
        "                                    # Importantly, it uses the same mean and standard deviation values that were computed from the training set.\n",
        "\n",
        "X_train_std\n",
        "\n",
        "# Fit models ( KNN and Logistic)\n",
        "\n",
        "# K-NN model\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train_std,y_train)\n",
        "\n",
        "#Logistic regression modelm\n",
        "log_reg = linear_model.LogisticRegression(solver='lbfgs',max_iter=500)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "\"\"\"### The below function was adopted from class code\"\"\"\n",
        "\n",
        "# Function that prints and plots the confusion matrix.\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]         # devide absolute number of observations with sum across columns to get the relative percentage of observations\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)                 # shows the confusion matrix in the console\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))                        # add tick marks to the confusion matrix\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'                        # choose format depending on whether the confusion matrix is normalizaed or not\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):      # loop that adds the value to each cell of the confusion matrix\n",
        "        plt.text(j, i, format(cm[i, j], fmt),                   # we reformat how the cell values are displayed accroding to the variable fmt we defined before\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# k-NN and Logistic predictions\n",
        "k_nn_pred = knn.predict(X_test_std)\n",
        "log_reg_pred = log_reg.predict(X_test)\n",
        "\n",
        "# k-NN Compute confusion matrix to evaluate the accuracy of a classification\n",
        "knn_cnf_matrix = confusion_matrix(y_test, k_nn_pred)\n",
        "knn_accuracy = accuracy_score(y_test, k_nn_pred)\n",
        "knn_report = classification_report(y_test, k_nn_pred)\n",
        "\n",
        "\n",
        "# Logistic Regression Compute confusion matrix to evaluate the accuracy of a classification\n",
        "log_reg_cnf_matrix = confusion_matrix(y_test, log_reg_pred)\n",
        "log_reg_accuracy = accuracy_score(y_test, log_reg_pred)\n",
        "log_reg_report = classification_report(y_test, log_reg_pred)\n",
        "\n",
        "#print KNN performance\n",
        "print(\"K-NN Evaluation:\")\n",
        "print(\"Confusion Matrix:\\n\", knn_cnf_matrix)\n",
        "print(\"Accuracy:\", knn_accuracy)\n",
        "print(\"Classification Report:\\n\", knn_report)\n",
        "\n",
        "#print KNN performance\n",
        "print(\"\\nLogistic Regression Evaluation:\")\n",
        "print(\"Confusion Matrix:\\n\", log_reg_cnf_matrix)\n",
        "print(\"Accuracy:\", log_reg_accuracy)\n",
        "print(\"Classification Report:\\n\", log_reg_report)\n",
        "\n",
        "print(\"\\nLogistic Regression Evaluation:\")\n",
        "print(\"Confusion Matrix:\\n\", log_reg_cnf_matrix)\n",
        "print(\"Accuracy:\", log_reg_accuracy)\n",
        "print(\"Classification Report:\\n\", log_reg_report)\n",
        "\n",
        "\"\"\"# 6. Model Evaluation\"\"\"\n",
        "\n",
        "# def evaluate_model(model, model_type, X_test, X_test_std, y_test):\n",
        "#     if model_type == 'knn':\n",
        "#         y_pred = model.predict(X_test_std)\n",
        "#     if model_type =='log_reg':\n",
        "#         y_pred = model.predict(X_test)\n",
        "\n",
        "#     # Compute confusion matrix to evaluate the accuracy of a classification\n",
        "#     cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "#     accuracy = accuracy_score(y_test, y_pred)\n",
        "#     report = classification_report(y_test, y_pred)\n",
        "\n",
        "#     return cnf_matrix, accuracy, report\n",
        "\n",
        "# # Assuming knn and log_reg are your trained models, and X_test and X_test_std are your test datasets\n",
        "# # Evaluate K-NN model\n",
        "# knn_cm, knn_accuracy, knn_report = evaluate_model(model=knn, model_type='knn', X_test=X_test, X_test_std=X_test_std, y_test=y_test)\n",
        "\n",
        "# # Evaluate Logistic model\n",
        "# log_reg_cm, log_reg_accuracy, log_reg_report = evaluate_model(model=log_reg, model_type='log_reg', X_test=X_test, X_test_std=X_test_std, y_test=y_test)\n",
        "\n",
        "# print(\"K-NN Evaluation:\")\n",
        "# print(\"Confusion Matrix:\\n\", knn_cm)\n",
        "# print(\"Accuracy:\", knn_accuracy)\n",
        "# print(\"Classification Report:\\n\", knn_report)\n",
        "\n",
        "# print(\"\\nLogistic Regression Evaluation:\")\n",
        "# print(\"Confusion Matrix:\\n\", log_reg_cm)\n",
        "# print(\"Accuracy:\", log_reg_accuracy)\n",
        "# print(\"Classification Report:\\n\", log_reg_report)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(knn_cnf_matrix,\n",
        "                      classes=class_names,\n",
        "                      title='k-NN Confusion matrix, without normalization')\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(log_reg_cnf_matrix,\n",
        "                      classes=class_names,\n",
        "                      title='Logistic Confusion matrix, without normalization')\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(log_reg_cnf_matrix,\n",
        "                      classes=class_names,\n",
        "                      title='Logistic Confusion matrix, without normalization')\n"
      ]
    }
  ]
}